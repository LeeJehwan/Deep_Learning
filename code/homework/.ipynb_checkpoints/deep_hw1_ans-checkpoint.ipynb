{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient descent 구현하기\n",
    "\n",
    "\n",
    "단순한 gradient descent함수를 numpy와 파이썬을 사용하여 구현해 보자.\n",
    "\n",
    "아래 함수는 W, X, Y를 인자로 받아 주어진 step 만큼 학습하는 함수이다.\n",
    "각 step수 마다 W를 개선하며 W와 cost를 출력해 보는 함수이다.\n",
    "\n",
    "##### hint: 아래 식은 W 개선 시 사용되는 식이다. (bias는 고려하지 않는다)\n",
    "<img src=\"./images/1.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def grad(W, X, Y, learning_rate = 0.1, step = 101):\n",
    "    for step in range(step):\n",
    "        hypothesis = np.matmul(X, W)\n",
    "        gradient = np.mean((hypothesis - Y)*X)\n",
    "        W = W - learning_rate * gradient\n",
    "        cost = np.mean(np.square(hypothesis - Y))\n",
    "        if step % 10 == 0:\n",
    "            print(step, W, cost)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 함수를 만들었다면 만든 함수를 가지고 간단한 예제를 통해 W를 학습 시켜보자.\n",
    "\n",
    "정상적으로 만들었다면 W는 2에 가까워야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[1.05912799]] 14.523470988737609\n",
      "10 [[1.99824807]] 5.0355275949019204e-05\n",
      "20 [[1.99999674]] 1.7459006996180482e-10\n",
      "30 [[1.99999999]] 6.053326310076167e-16\n",
      "40 [[2.]] 2.098779112731061e-21\n",
      "50 [[2.]] 7.32516515065601e-27\n",
      "60 [[2.]] 0.0\n",
      "70 [[2.]] 0.0\n",
      "80 [[2.]] 0.0\n",
      "90 [[2.]] 0.0\n",
      "100 [[2.]] 0.0\n",
      "W: [[2.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[1], [2], [3]])  # (3,1)\n",
    "Y = np.array([[2], [4], [6]])  # (3,1)\n",
    "W = np.random.random((1,1))    # (1,1)\n",
    "\n",
    "W = grad(W, X, Y)\n",
    "print(\"W:\",W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "### 논리회로 만들어보기\n",
    "\n",
    "우리는 기존에 과제로 AND게이트를 만들어 본 적이 있다. 당시 W의 값을 직접 구했었는데 이번엔 위에서 우리가 만든 gradient descent로 인공지능에게 구하라고 시켜보자\n",
    "\n",
    "\n",
    "* 다음은 AND게이트의 진리표이다.\n",
    "\n",
    "|x1|x2| y|\n",
    "|-|-|-|\n",
    "|0|0|0|\n",
    "|1|0|0|\n",
    "|0|1|0|\n",
    "|1|1|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.60114982]\n",
      " [0.81137127]] 0.33266995258675747\n",
      "10 [[0.39924044]\n",
      " [0.60946189]] 0.1401306862585915\n",
      "20 [[0.30664837]\n",
      " [0.51686982]] 0.09964010909326365\n",
      "30 [[0.26418728]\n",
      " [0.47440872]] 0.09112503125772743\n",
      "40 [[0.24471537]\n",
      " [0.45493682]] 0.08933432942976417\n",
      "50 [[0.2357859 ]\n",
      " [0.44600735]] 0.08895774883959166\n",
      "60 [[0.231691  ]\n",
      " [0.44191245]] 0.08887855478356284\n",
      "70 [[0.22981315]\n",
      " [0.4400346 ]] 0.08886190045066845\n",
      "80 [[0.228952  ]\n",
      " [0.43917345]] 0.08885839808170207\n",
      "90 [[0.2285571 ]\n",
      " [0.43877854]] 0.0888576615413402\n",
      "100 [[0.228376  ]\n",
      " [0.43859745]] 0.0888575066485491\n",
      "110 [[0.22829295]\n",
      " [0.4385144 ]] 0.08885747407494149\n",
      "120 [[0.22825487]\n",
      " [0.43847631]] 0.08885746722478466\n",
      "130 [[0.2282374 ]\n",
      " [0.43845885]] 0.08885746578421198\n",
      "140 [[0.22822939]\n",
      " [0.43845084]] 0.08885746548126279\n",
      "150 [[0.22822572]\n",
      " [0.43844717]] 0.08885746541755324\n",
      "160 [[0.22822404]\n",
      " [0.43844548]] 0.08885746540415526\n",
      "170 [[0.22822326]\n",
      " [0.43844471]] 0.08885746540133771\n",
      "180 [[0.22822291]\n",
      " [0.43844436]] 0.0888574654007452\n",
      "190 [[0.22822275]\n",
      " [0.43844419]] 0.08885746540062056\n",
      "200 [[0.22822267]\n",
      " [0.43844412]] 0.08885746540059439\n",
      "210 [[0.22822264]\n",
      " [0.43844409]] 0.08885746540058886\n",
      "220 [[0.22822262]\n",
      " [0.43844407]] 0.08885746540058773\n",
      "230 [[0.22822262]\n",
      " [0.43844406]] 0.08885746540058746\n",
      "240 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058741\n",
      "250 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058741\n",
      "260 [[0.22822261]\n",
      " [0.43844406]] 0.0888574654005874\n",
      "270 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058741\n",
      "280 [[0.22822261]\n",
      " [0.43844406]] 0.0888574654005874\n",
      "290 [[0.22822261]\n",
      " [0.43844406]] 0.0888574654005874\n",
      "300 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058741\n",
      "310 [[0.22822261]\n",
      " [0.43844406]] 0.0888574654005874\n",
      "320 [[0.22822261]\n",
      " [0.43844406]] 0.0888574654005874\n",
      "330 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "340 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058741\n",
      "350 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "360 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "370 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "380 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058741\n",
      "390 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "400 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "410 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "420 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "430 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "440 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "450 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058742\n",
      "460 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "470 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "480 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "490 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "500 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "510 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "520 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "530 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "540 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "550 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "560 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "570 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "580 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "590 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "600 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "610 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "620 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "630 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "640 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "650 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "660 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "670 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "680 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "690 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "700 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "710 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "720 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "730 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "740 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "750 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "760 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "770 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "780 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "790 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "800 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "810 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "820 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "830 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "840 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "850 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "860 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "870 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "880 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "890 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "900 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "910 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "920 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "930 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "940 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "950 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "960 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "970 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "980 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n",
      "990 [[0.22822261]\n",
      " [0.43844406]] 0.08885746540058745\n"
     ]
    }
   ],
   "source": [
    "# insert your code\n",
    "# 행렬의 size에 유의하자\n",
    "# 다른 게이트와 구분하기 위해 W의 이름을 W_and 라 하자.\n",
    "\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[0],[0],[1]])\n",
    "W_and = np.random.random((2,1))\n",
    "\n",
    "W_and = grad(W_and, x, y, step = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 끝났다면 학습한 W값을 가지고 AND게이트가 학습이 제대로 이뤄졌는지 확인해보자.\n",
    "만일 학습이 제대로 이루어지지 않았다면 learning_rate나 step을 변경시켜 튜닝을 해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    y = np.matmul(x, W_and)\n",
    "    if y >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(AND(0,0))\n",
    "print(AND(1,0))\n",
    "print(AND(0,1))\n",
    "print(AND(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로 OR게이트와 NAND게이트도 만들어 보자.\n",
    "\n",
    "* 다음은 OR게이트의 진리표이다.\n",
    "\n",
    "|x1|x2| y|\n",
    "|-|-|-|\n",
    "|0|0|0|\n",
    "|1|0|1|\n",
    "|0|1|1|\n",
    "|1|1|1|\n",
    "\n",
    "* 다음은 NAND게이트의 진리표이다.\n",
    "\n",
    "|x1|x2| y|\n",
    "|-|-|-|\n",
    "|0|0|1|\n",
    "|1|0|1|\n",
    "|0|1|1|\n",
    "|1|1|0|\n",
    "\n",
    "여기서도 W_or로 가중치의 이름을 정해 주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.33506207]\n",
      " [0.38183262]] 0.2501502033656422\n",
      "10 [[0.50193746]\n",
      " [0.548708  ]] 0.1186304806769155\n",
      "20 [[0.57846356]\n",
      " [0.6252341 ]] 0.09097217709112174\n",
      "30 [[0.61355708]\n",
      " [0.66032762]] 0.08515569769468594\n",
      "40 [[0.62965035]\n",
      " [0.67642089]] 0.08393250508403936\n",
      "50 [[0.63703044]\n",
      " [0.68380098]] 0.08367527041324223\n",
      "60 [[0.64041482]\n",
      " [0.68718536]] 0.08362117453718466\n",
      "70 [[0.64196683]\n",
      " [0.68873738]] 0.08360979829541532\n",
      "80 [[0.64267856]\n",
      " [0.6894491 ]] 0.08360740589721005\n",
      "90 [[0.64300495]\n",
      " [0.68977549]] 0.08360690278121721\n",
      "100 [[0.64315462]\n",
      " [0.68992516]] 0.0836067969770489\n",
      "110 [[0.64322326]\n",
      " [0.6899938 ]] 0.08360677472666896\n",
      "120 [[0.64325473]\n",
      " [0.69002528]] 0.0836067700474638\n",
      "130 [[0.64326917]\n",
      " [0.69003971]] 0.0836067690634374\n",
      "140 [[0.64327579]\n",
      " [0.69004633]] 0.08360676885649883\n",
      "150 [[0.64327882]\n",
      " [0.69004937]] 0.08360676881298015\n",
      "160 [[0.64328022]\n",
      " [0.69005076]] 0.08360676880382822\n",
      "170 [[0.64328085]\n",
      " [0.6900514 ]] 0.08360676880190365\n",
      "180 [[0.64328115]\n",
      " [0.69005169]] 0.08360676880149887\n",
      "190 [[0.64328128]\n",
      " [0.69005182]] 0.08360676880141378\n"
     ]
    }
   ],
   "source": [
    "# insert your code\n",
    "# 다른 게이트와 구분하기 위해 W의 이름을 W_or 라 하자.\n",
    "\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[1],[1],[1]])\n",
    "W_or = np.random.random((2,1))\n",
    "\n",
    "W_or = grad(W_and, x, y, step = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    y = np.matmul(x, W_or)\n",
    "    if y >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(OR(0,0))\n",
    "print(OR(1,0))\n",
    "print(OR(0,1))\n",
    "print(OR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAND게이트의 경우 AND게이트를 반전시켜주면 되므로 별도로 학습을 하지 않아도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make nand function\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    return int(not AND(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(NAND(0,0))\n",
    "print(NAND(1,0))\n",
    "print(NAND(0,1))\n",
    "print(NAND(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 XOR게이트를 만들어보자\n",
    "기존과 같은 방식으로 학습시켜보자.\n",
    "\n",
    "* 다음은 XOR게이트의 진리표이다.\n",
    "\n",
    "|x1|x2| y|\n",
    "|-|-|-|\n",
    "|0|0|0|\n",
    "|1|0|1|\n",
    "|0|1|1|\n",
    "|1|1|0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.72535026]\n",
      " [0.17669556]] 0.3917376459091618\n",
      "10 [[0.72534143]\n",
      " [0.17668673]] 0.39173452964646693\n",
      "20 [[0.7253326]\n",
      " [0.1766779]] 0.3917314138511784\n",
      "30 [[0.72532378]\n",
      " [0.17666908]] 0.39172829852322566\n",
      "40 [[0.72531495]\n",
      " [0.17666025]] 0.3917251836625389\n",
      "50 [[0.72530613]\n",
      " [0.17665143]] 0.39172206926904796\n",
      "60 [[0.72529731]\n",
      " [0.17664261]] 0.39171895534268275\n",
      "70 [[0.72528849]\n",
      " [0.17663378]] 0.39171584188337305\n",
      "80 [[0.72527966]\n",
      " [0.17662496]] 0.39171272889104924\n",
      "90 [[0.72527084]\n",
      " [0.17661614]] 0.39170961636564083\n",
      "100 [[0.72526202]\n",
      " [0.17660732]] 0.391706504307078\n",
      "110 [[0.7252532]\n",
      " [0.1765985]] 0.39170339271529075\n",
      "120 [[0.72524438]\n",
      " [0.17658968]] 0.391700281590209\n",
      "130 [[0.72523556]\n",
      " [0.17658086]] 0.3916971709317627\n",
      "140 [[0.72522675]\n",
      " [0.17657205]] 0.3916940607398819\n",
      "150 [[0.72521793]\n",
      " [0.17656323]] 0.3916909510144967\n",
      "160 [[0.72520911]\n",
      " [0.17655441]] 0.3916878417555371\n",
      "170 [[0.7252003]\n",
      " [0.1765456]] 0.39168473296293305\n",
      "180 [[0.72519148]\n",
      " [0.17653678]] 0.3916816246366147\n",
      "190 [[0.72518267]\n",
      " [0.17652797]] 0.3916785167765121\n",
      "200 [[0.72517385]\n",
      " [0.17651915]] 0.3916754093825553\n",
      "210 [[0.72516504]\n",
      " [0.17651034]] 0.3916723024546743\n",
      "220 [[0.72515623]\n",
      " [0.17650153]] 0.39166919599279937\n",
      "230 [[0.72514742]\n",
      " [0.17649271]] 0.3916660899968605\n",
      "240 [[0.72513861]\n",
      " [0.1764839 ]] 0.3916629844667878\n",
      "250 [[0.72512979]\n",
      " [0.17647509]] 0.3916598794025114\n",
      "260 [[0.72512098]\n",
      " [0.17646628]] 0.39165677480396155\n",
      "270 [[0.72511218]\n",
      " [0.17645747]] 0.39165367067106827\n",
      "280 [[0.72510337]\n",
      " [0.17644867]] 0.3916505670037618\n",
      "290 [[0.72509456]\n",
      " [0.17643986]] 0.39164746380197213\n",
      "300 [[0.72508575]\n",
      " [0.17643105]] 0.39164436106562966\n",
      "310 [[0.72507695]\n",
      " [0.17642224]] 0.3916412587946645\n",
      "320 [[0.72506814]\n",
      " [0.17641344]] 0.3916381569890067\n",
      "330 [[0.72505933]\n",
      " [0.17640463]] 0.3916350556485868\n",
      "340 [[0.72505053]\n",
      " [0.17639583]] 0.3916319547733347\n",
      "350 [[0.72504173]\n",
      " [0.17638702]] 0.39162885436318073\n",
      "360 [[0.72503292]\n",
      " [0.17637822]] 0.3916257544180552\n",
      "370 [[0.72502412]\n",
      " [0.17636942]] 0.3916226549378883\n",
      "380 [[0.72501532]\n",
      " [0.17636062]] 0.39161955592261033\n",
      "390 [[0.72500652]\n",
      " [0.17635181]] 0.39161645737215145\n",
      "400 [[0.72499772]\n",
      " [0.17634301]] 0.39161335928644203\n",
      "410 [[0.72498892]\n",
      " [0.17633421]] 0.39161026166541246\n",
      "420 [[0.72498012]\n",
      " [0.17632541]] 0.39160716450899286\n",
      "430 [[0.72497132]\n",
      " [0.17631662]] 0.39160406781711365\n",
      "440 [[0.72496252]\n",
      " [0.17630782]] 0.39160097158970514\n",
      "450 [[0.72495372]\n",
      " [0.17629902]] 0.3915978758266976\n",
      "460 [[0.72494493]\n",
      " [0.17629022]] 0.3915947805280213\n",
      "470 [[0.72493613]\n",
      " [0.17628143]] 0.39159168569360703\n",
      "480 [[0.72492733]\n",
      " [0.17627263]] 0.39158859132338464\n",
      "490 [[0.72491854]\n",
      " [0.17626384]] 0.39158549741728477\n",
      "500 [[0.72490975]\n",
      " [0.17625504]] 0.3915824039752377\n",
      "510 [[0.72490095]\n",
      " [0.17624625]] 0.3915793109971739\n",
      "520 [[0.72489216]\n",
      " [0.17623746]] 0.3915762184830238\n",
      "530 [[0.72488337]\n",
      " [0.17622867]] 0.3915731264327178\n",
      "540 [[0.72487458]\n",
      " [0.17621987]] 0.3915700348461863\n",
      "550 [[0.72486579]\n",
      " [0.17621108]] 0.3915669437233597\n",
      "560 [[0.724857  ]\n",
      " [0.17620229]] 0.3915638530641685\n",
      "570 [[0.72484821]\n",
      " [0.1761935 ]] 0.39156076286854324\n",
      "580 [[0.72483942]\n",
      " [0.17618472]] 0.39155767313641415\n",
      "590 [[0.72483063]\n",
      " [0.17617593]] 0.3915545838677119\n",
      "600 [[0.72482184]\n",
      " [0.17616714]] 0.3915514950623669\n",
      "610 [[0.72481305]\n",
      " [0.17615835]] 0.39154840672030977\n",
      "620 [[0.72480427]\n",
      " [0.17614957]] 0.3915453188414709\n",
      "630 [[0.72479548]\n",
      " [0.17614078]] 0.3915422314257808\n",
      "640 [[0.7247867]\n",
      " [0.176132 ]] 0.3915391444731702\n",
      "650 [[0.72477791]\n",
      " [0.17612321]] 0.3915360579835694\n",
      "660 [[0.72476913]\n",
      " [0.17611443]] 0.39153297195690906\n",
      "670 [[0.72476035]\n",
      " [0.17610565]] 0.3915298863931198\n",
      "680 [[0.72475157]\n",
      " [0.17609686]] 0.3915268012921321\n",
      "690 [[0.72474278]\n",
      " [0.17608808]] 0.3915237166538766\n",
      "700 [[0.724734 ]\n",
      " [0.1760793]] 0.3915206324782838\n",
      "710 [[0.72472522]\n",
      " [0.17607052]] 0.39151754876528444\n",
      "720 [[0.72471644]\n",
      " [0.17606174]] 0.39151446551480906\n",
      "730 [[0.72470766]\n",
      " [0.17605296]] 0.3915113827267883\n",
      "740 [[0.72469889]\n",
      " [0.17604418]] 0.3915083004011528\n",
      "750 [[0.72469011]\n",
      " [0.17603541]] 0.39150521853783327\n",
      "760 [[0.72468133]\n",
      " [0.17602663]] 0.3915021371367602\n",
      "770 [[0.72467256]\n",
      " [0.17601785]] 0.39149905619786435\n",
      "780 [[0.72466378]\n",
      " [0.17600908]] 0.3914959757210764\n",
      "790 [[0.72465501]\n",
      " [0.1760003 ]] 0.39149289570632717\n",
      "800 [[0.72464623]\n",
      " [0.17599153]] 0.39148981615354705\n",
      "810 [[0.72463746]\n",
      " [0.17598276]] 0.39148673706266707\n",
      "820 [[0.72462868]\n",
      " [0.17597398]] 0.39148365843361776\n",
      "830 [[0.72461991]\n",
      " [0.17596521]] 0.3914805802663299\n",
      "840 [[0.72461114]\n",
      " [0.17595644]] 0.3914775025607343\n",
      "850 [[0.72460237]\n",
      " [0.17594767]] 0.3914744253167616\n",
      "860 [[0.7245936]\n",
      " [0.1759389]] 0.3914713485343426\n",
      "870 [[0.72458483]\n",
      " [0.17593013]] 0.3914682722134082\n",
      "880 [[0.72457606]\n",
      " [0.17592136]] 0.3914651963538889\n",
      "890 [[0.72456729]\n",
      " [0.17591259]] 0.39146212095571575\n",
      "900 [[0.72455852]\n",
      " [0.17590382]] 0.3914590460188194\n",
      "910 [[0.72454976]\n",
      " [0.17589506]] 0.3914559715431308\n",
      "920 [[0.72454099]\n",
      " [0.17588629]] 0.3914528975285807\n",
      "930 [[0.72453223]\n",
      " [0.17587752]] 0.39144982397509986\n",
      "940 [[0.72452346]\n",
      " [0.17586876]] 0.39144675088261927\n",
      "950 [[0.7245147 ]\n",
      " [0.17585999]] 0.3914436782510695\n",
      "960 [[0.72450593]\n",
      " [0.17585123]] 0.3914406060803818\n",
      "970 [[0.72449717]\n",
      " [0.17584247]] 0.3914375343704868\n",
      "980 [[0.72448841]\n",
      " [0.1758337 ]] 0.39143446312131547\n",
      "990 [[0.72447964]\n",
      " [0.17582494]] 0.39143139233279867\n",
      "1000 [[0.72447088]\n",
      " [0.17581618]] 0.39142832200486743\n",
      "1010 [[0.72446212]\n",
      " [0.17580742]] 0.3914252521374526\n",
      "1020 [[0.72445336]\n",
      " [0.17579866]] 0.3914221827304849\n",
      "1030 [[0.7244446]\n",
      " [0.1757899]] 0.3914191137838956\n",
      "1040 [[0.72443585]\n",
      " [0.17578114]] 0.3914160452976154\n",
      "1050 [[0.72442709]\n",
      " [0.17577239]] 0.3914129772715754\n",
      "1060 [[0.72441833]\n",
      " [0.17576363]] 0.39140990970570655\n",
      "1070 [[0.72440957]\n",
      " [0.17575487]] 0.3914068425999397\n",
      "1080 [[0.72440082]\n",
      " [0.17574612]] 0.39140377595420595\n",
      "1090 [[0.72439206]\n",
      " [0.17573736]] 0.39140070976843633\n",
      "1100 [[0.72438331]\n",
      " [0.17572861]] 0.39139764404256183\n",
      "1110 [[0.72437455]\n",
      " [0.17571985]] 0.3913945787765135\n",
      "1120 [[0.7243658]\n",
      " [0.1757111]] 0.3913915139702222\n",
      "1130 [[0.72435705]\n",
      " [0.17570235]] 0.3913884496236192\n",
      "1140 [[0.7243483]\n",
      " [0.1756936]] 0.3913853857366354\n",
      "1150 [[0.72433955]\n",
      " [0.17568484]] 0.3913823223092019\n",
      "1160 [[0.72433079]\n",
      " [0.17567609]] 0.39137925934124973\n",
      "1170 [[0.72432204]\n",
      " [0.17566734]] 0.3913761968327101\n",
      "1180 [[0.7243133 ]\n",
      " [0.17565859]] 0.39137313478351393\n",
      "1190 [[0.72430455]\n",
      " [0.17564985]] 0.3913700731935924\n",
      "1200 [[0.7242958]\n",
      " [0.1756411]] 0.3913670120628767\n",
      "1210 [[0.72428705]\n",
      " [0.17563235]] 0.39136395139129787\n",
      "1220 [[0.7242783]\n",
      " [0.1756236]] 0.39136089117878703\n",
      "1230 [[0.72426956]\n",
      " [0.17561486]] 0.39135783142527536\n",
      "1240 [[0.72426081]\n",
      " [0.17560611]] 0.3913547721306941\n",
      "1250 [[0.72425207]\n",
      " [0.17559737]] 0.3913517132949743\n",
      "1260 [[0.72424332]\n",
      " [0.17558862]] 0.39134865491804716\n",
      "1270 [[0.72423458]\n",
      " [0.17557988]] 0.39134559699984395\n",
      "1280 [[0.72422584]\n",
      " [0.17557114]] 0.3913425395402957\n",
      "1290 [[0.7242171 ]\n",
      " [0.17556239]] 0.3913394825393337\n",
      "1300 [[0.72420835]\n",
      " [0.17555365]] 0.3913364259968892\n",
      "1310 [[0.72419961]\n",
      " [0.17554491]] 0.39133336991289336\n",
      "1320 [[0.72419087]\n",
      " [0.17553617]] 0.39133031428727755\n",
      "1330 [[0.72418213]\n",
      " [0.17552743]] 0.39132725911997285\n",
      "1340 [[0.7241734 ]\n",
      " [0.17551869]] 0.39132420441091054\n",
      "1350 [[0.72416466]\n",
      " [0.17550996]] 0.3913211501600221\n",
      "1360 [[0.72415592]\n",
      " [0.17550122]] 0.3913180963672386\n",
      "1370 [[0.72414718]\n",
      " [0.17549248]] 0.3913150430324913\n",
      "1380 [[0.72413845]\n",
      " [0.17548375]] 0.3913119901557117\n",
      "1390 [[0.72412971]\n",
      " [0.17547501]] 0.39130893773683095\n",
      "1400 [[0.72412098]\n",
      " [0.17546628]] 0.3913058857757804\n",
      "1410 [[0.72411224]\n",
      " [0.17545754]] 0.39130283427249135\n",
      "1420 [[0.72410351]\n",
      " [0.17544881]] 0.3912997832268953\n",
      "1430 [[0.72409478]\n",
      " [0.17544007]] 0.3912967326389234\n",
      "1440 [[0.72408604]\n",
      " [0.17543134]] 0.39129368250850705\n",
      "1450 [[0.72407731]\n",
      " [0.17542261]] 0.39129063283557775\n",
      "1460 [[0.72406858]\n",
      " [0.17541388]] 0.3912875836200668\n",
      "1470 [[0.72405985]\n",
      " [0.17540515]] 0.3912845348619057\n",
      "1480 [[0.72405112]\n",
      " [0.17539642]] 0.39128148656102546\n",
      "1490 [[0.72404239]\n",
      " [0.17538769]] 0.3912784387173579\n",
      "1500 [[0.72403366]\n",
      " [0.17537896]] 0.39127539133083433\n",
      "1510 [[0.72402494]\n",
      " [0.17537023]] 0.39127234440138625\n",
      "1520 [[0.72401621]\n",
      " [0.17536151]] 0.3912692979289449\n",
      "1530 [[0.72400748]\n",
      " [0.17535278]] 0.39126625191344183\n",
      "1540 [[0.72399876]\n",
      " [0.17534406]] 0.39126320635480855\n",
      "1550 [[0.72399003]\n",
      " [0.17533533]] 0.3912601612529766\n",
      "1560 [[0.72398131]\n",
      " [0.17532661]] 0.3912571166078773\n",
      "1570 [[0.72397258]\n",
      " [0.17531788]] 0.3912540724194423\n",
      "1580 [[0.72396386]\n",
      " [0.17530916]] 0.391251028687603\n",
      "1590 [[0.72395514]\n",
      " [0.17530044]] 0.391247985412291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 [[0.72394642]\n",
      " [0.17529171]] 0.3912449425934377\n",
      "1610 [[0.7239377 ]\n",
      " [0.17528299]] 0.3912419002309747\n",
      "1620 [[0.72392897]\n",
      " [0.17527427]] 0.3912388583248336\n",
      "1630 [[0.72392025]\n",
      " [0.17526555]] 0.39123581687494596\n",
      "1640 [[0.72391154]\n",
      " [0.17525683]] 0.3912327758812432\n",
      "1650 [[0.72390282]\n",
      " [0.17524812]] 0.3912297353436571\n",
      "1660 [[0.7238941]\n",
      " [0.1752394]] 0.39122669526211906\n",
      "1670 [[0.72388538]\n",
      " [0.17523068]] 0.3912236556365608\n",
      "1680 [[0.72387667]\n",
      " [0.17522196]] 0.39122061646691386\n",
      "1690 [[0.72386795]\n",
      " [0.17521325]] 0.39121757775310995\n",
      "1700 [[0.72385923]\n",
      " [0.17520453]] 0.39121453949508056\n",
      "1710 [[0.72385052]\n",
      " [0.17519582]] 0.3912115016927575\n",
      "1720 [[0.72384181]\n",
      " [0.1751871 ]] 0.39120846434607226\n",
      "1730 [[0.72383309]\n",
      " [0.17517839]] 0.39120542745495657\n",
      "1740 [[0.72382438]\n",
      " [0.17516968]] 0.39120239101934207\n",
      "1750 [[0.72381567]\n",
      " [0.17516097]] 0.39119935503916053\n",
      "1760 [[0.72380696]\n",
      " [0.17515226]] 0.3911963195143434\n",
      "1770 [[0.72379825]\n",
      " [0.17514354]] 0.3911932844448227\n",
      "1780 [[0.72378954]\n",
      " [0.17513483]] 0.39119024983052997\n",
      "1790 [[0.72378083]\n",
      " [0.17512613]] 0.3911872156713969\n",
      "1800 [[0.72377212]\n",
      " [0.17511742]] 0.39118418196735527\n",
      "1810 [[0.72376341]\n",
      " [0.17510871]] 0.39118114871833687\n",
      "1820 [[0.7237547]\n",
      " [0.1751   ]] 0.3911781159242733\n",
      "1830 [[0.723746  ]\n",
      " [0.17509129]] 0.3911750835850966\n",
      "1840 [[0.72373729]\n",
      " [0.17508259]] 0.3911720517007383\n",
      "1850 [[0.72372858]\n",
      " [0.17507388]] 0.3911690202711303\n",
      "1860 [[0.72371988]\n",
      " [0.17506518]] 0.39116598929620433\n",
      "1870 [[0.72371118]\n",
      " [0.17505647]] 0.39116295877589213\n",
      "1880 [[0.72370247]\n",
      " [0.17504777]] 0.3911599287101257\n",
      "1890 [[0.72369377]\n",
      " [0.17503907]] 0.39115689909883666\n",
      "1900 [[0.72368507]\n",
      " [0.17503037]] 0.391153869941957\n",
      "1910 [[0.72367637]\n",
      " [0.17502166]] 0.39115084123941835\n",
      "1920 [[0.72366766]\n",
      " [0.17501296]] 0.39114781299115287\n",
      "1930 [[0.72365896]\n",
      " [0.17500426]] 0.3911447851970922\n",
      "1940 [[0.72365026]\n",
      " [0.17499556]] 0.3911417578571683\n",
      "1950 [[0.72364157]\n",
      " [0.17498686]] 0.391138730971313\n",
      "1960 [[0.72363287]\n",
      " [0.17497817]] 0.39113570453945834\n",
      "1970 [[0.72362417]\n",
      " [0.17496947]] 0.39113267856153605\n",
      "1980 [[0.72361547]\n",
      " [0.17496077]] 0.39112965303747815\n",
      "1990 [[0.72360678]\n",
      " [0.17495207]] 0.3911266279672165\n"
     ]
    }
   ],
   "source": [
    "# insert your code\n",
    "# 다른 게이트와 구분하기 위해 W의 이름을 W_xor 라 하자.\n",
    "\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "W_xor = np.random.random((2,1))\n",
    "\n",
    "W_xor = grad(W_xor, x, y, learning_rate = 1e-5, step = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    y = np.matmul(x, W_xor)\n",
    "    if y >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(XOR(0,0))\n",
    "print(XOR(1,0))\n",
    "print(XOR(0,1))\n",
    "print(XOR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아마 아무리 학습을 하여도 제대로 된 결과가 나오지 않을 것 이다. \n",
    "이는 단순 직선으로는 XOR게이트를 만들 수 없기 떄문이다.\n",
    "\n",
    "<img src=\"./images/2.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 비선형 구조는 선형 구조의 분류자를 층을 쌓아서 조합해 비선형 구조로 만들어야한다.\n",
    "\n",
    "따라서 우리는 우리가 만든 AND, OR, NAND게이트를 조합하여 XOR를 만들어야 한다.\n",
    "\n",
    "\n",
    "\n",
    "##### hint: 조합 방법은 다음과 같다.\n",
    "\n",
    "<img src=\"./images/3.png\" width=60%/>\n",
    "\n",
    "\n",
    "위 방법은 마치 신경망 구조와 같다. 따라서 이를 다시 신경망 처럼 표현하면 다음과 같다.\n",
    "\n",
    "<img src=\"./images/4.png\" width=80%/>\n",
    "\n",
    "위 구조를 이용해서 XOR게이트 함수를 직접 구현해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make XOR gate\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    s1 = NAND(x1,x2)\n",
    "    s2 = OR(x1,x2)\n",
    "    return AND(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(XOR(0,0))\n",
    "print(XOR(1,0))\n",
    "print(XOR(0,1))\n",
    "print(XOR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example1\n",
    "\n",
    "### tensorflow 기초 실습\n",
    "\n",
    "앞에서 XOR게이트를 만들 때 본 신경망 구조는 tensorflow의 작동방식과 일치한다.\n",
    "\n",
    "tensorflow를 익히기 위해 간단한 예제를 실습해 보자.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/5.png\" width=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.int32, name=\"input_a\")\n",
    "b = tf.placeholder(tf.int32, name=\"input_b\")\n",
    "\n",
    "c = tf.add(a, b, name=\"add\")\n",
    "d = tf.multiply(a, b, name=\"multiply\")\n",
    "e = tf.subtract(c, d, name=\"subtract\")\n",
    "out = tf.add(b, e, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 tensorflow를 이용하여 operation(Node)와 tensor(edge)를 정의하여 그래프를 정의해준다. \n",
    "\n",
    "이는 단순히 그래프를 정의한 것으로 Session 객체로 run 하기 전까지는 실행이 안된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: -8\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "input_data = { a: 7, b: 3 }\n",
    "result = sess.run(out, feed_dict=input_data)\n",
    "print(\"out:\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "### tensorflow를 이용하여 계산해보기\n",
    "\n",
    "다음 그래프를 정의하고 계산해 보자.\n",
    "<img src=\"./images/6.png\" width=70%/>\n",
    "\n",
    "\n",
    "tensorflow의 수학 관련 Operations 에 관한 설명은 [이곳을 참고하자](https://www.tensorflow.org/api_guides/python/math_ops)\n",
    "\n",
    "그래프 실행 후 결과는 다음과 같다\n",
    "\n",
    "|In | Out|\n",
    "|---|----|\n",
    "|1, 2, 3| 15|\n",
    "|-1, -2, 3| -3|\n",
    "|123, 456, 789|44613795|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "in1 = tf.placeholder(tf.int32, name=\"input_1\")\n",
    "in2 = tf.placeholder(tf.int32, name=\"input_2\")\n",
    "in3 = tf.placeholder(tf.int32, name=\"input_3\")\n",
    "\n",
    "prod_list = [in1, in2, in3]\n",
    "a = tf.add(in1, in2, name = \"add\")\n",
    "b = tf.reduce_prod(prod_list, name = \"product\")\n",
    "c = tf.multiply(in2, in3, name = \"mul\")\n",
    "\n",
    "sum_list = [a, b, c]\n",
    "out = tf.reduce_sum(sum_list, name='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: 15\n",
      "out: -3\n",
      "out: 44613795\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "input_data1 = { in1: 1, in2: 2, in3: 3}\n",
    "input_data2 = { in1: -1, in2: -2, in3: 3}\n",
    "input_data3 = { in1: 123, in2: 456, in3: 789}\n",
    "\n",
    "\n",
    "result1 = sess.run(out, feed_dict=input_data1)\n",
    "result2 = sess.run(out, feed_dict=input_data2)\n",
    "result3 = sess.run(out, feed_dict=input_data3)\n",
    "print(\"out:\",result1)\n",
    "print(\"out:\",result2)\n",
    "print(\"out:\",result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
