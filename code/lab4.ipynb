{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab04 multi variable linear regression\n",
    "\n",
    "\n",
    "## 실습1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 142.]\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name = 'weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name = 'weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name = 'weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 3.8059742 \n",
      "Prediction:\n",
      " [154.4352  181.66464 181.3662  195.75433 142.21964]\n",
      "10 Cost: 3.7963862 \n",
      "Prediction:\n",
      " [154.43141 181.66895 181.36584 195.75386 142.21938]\n",
      "20 Cost: 3.7868474 \n",
      "Prediction:\n",
      " [154.4276  181.67322 181.36554 195.75336 142.21909]\n",
      "30 Cost: 3.777287 \n",
      "Prediction:\n",
      " [154.42381 181.67752 181.36519 195.75288 142.21884]\n",
      "40 Cost: 3.7678235 \n",
      "Prediction:\n",
      " [154.42001 181.68176 181.36487 195.75237 142.21855]\n",
      "50 Cost: 3.758305 \n",
      "Prediction:\n",
      " [154.41623 181.68607 181.36455 195.7519  142.2183 ]\n",
      "60 Cost: 3.7488747 \n",
      "Prediction:\n",
      " [154.41246 181.69032 181.36423 195.75142 142.21803]\n",
      "70 Cost: 3.7394645 \n",
      "Prediction:\n",
      " [154.40868 181.69456 181.3639  195.75093 142.21777]\n",
      "80 Cost: 3.7300408 \n",
      "Prediction:\n",
      " [154.40489 181.6988  181.36354 195.75044 142.21748]\n",
      "90 Cost: 3.7206597 \n",
      "Prediction:\n",
      " [154.40112 181.70306 181.36324 195.74995 142.21722]\n",
      "100 Cost: 3.7113633 \n",
      "Prediction:\n",
      " [154.39738 181.70729 181.36293 195.74947 142.21698]\n",
      "110 Cost: 3.702029 \n",
      "Prediction:\n",
      " [154.39362 181.71152 181.3626  195.749   142.2167 ]\n",
      "120 Cost: 3.6927478 \n",
      "Prediction:\n",
      " [154.38988 181.71574 181.36227 195.7485  142.21645]\n",
      "130 Cost: 3.683469 \n",
      "Prediction:\n",
      " [154.38614 181.71997 181.36194 195.74805 142.21619]\n",
      "140 Cost: 3.6742625 \n",
      "Prediction:\n",
      " [154.3824  181.72417 181.36163 195.74754 142.21591]\n",
      "150 Cost: 3.665012 \n",
      "Prediction:\n",
      " [154.37866 181.7284  181.3613  195.74707 142.21567]\n",
      "160 Cost: 3.6558394 \n",
      "Prediction:\n",
      " [154.37492 181.73257 181.36098 195.7466  142.2154 ]\n",
      "170 Cost: 3.6466603 \n",
      "Prediction:\n",
      " [154.37122 181.7368  181.36067 195.74612 142.21515]\n",
      "180 Cost: 3.6375237 \n",
      "Prediction:\n",
      " [154.36751 181.741   181.36035 195.74565 142.21489]\n",
      "190 Cost: 3.6284058 \n",
      "Prediction:\n",
      " [154.36378 181.74518 181.36003 195.74518 142.21463]\n",
      "200 Cost: 3.619336 \n",
      "Prediction:\n",
      " [154.36008 181.74934 181.35971 195.74469 142.21437]\n",
      "210 Cost: 3.6102703 \n",
      "Prediction:\n",
      " [154.35638 181.75352 181.35939 195.74423 142.21411]\n",
      "220 Cost: 3.6012444 \n",
      "Prediction:\n",
      " [154.35268 181.75768 181.35907 195.74374 142.21384]\n",
      "230 Cost: 3.592205 \n",
      "Prediction:\n",
      " [154.34898 181.76186 181.35875 195.74327 142.21358]\n",
      "240 Cost: 3.583241 \n",
      "Prediction:\n",
      " [154.3453  181.766   181.35844 195.7428  142.21332]\n",
      "250 Cost: 3.574271 \n",
      "Prediction:\n",
      " [154.34161 181.77014 181.3581  195.74231 142.21306]\n",
      "260 Cost: 3.5652852 \n",
      "Prediction:\n",
      " [154.33792 181.77432 181.3578  195.74185 142.2128 ]\n",
      "270 Cost: 3.5564048 \n",
      "Prediction:\n",
      " [154.33426 181.77844 181.35748 195.74136 142.21254]\n",
      "280 Cost: 3.5475154 \n",
      "Prediction:\n",
      " [154.3306  181.78258 181.35716 195.7409  142.2123 ]\n",
      "290 Cost: 3.538671 \n",
      "Prediction:\n",
      " [154.32695 181.78671 181.35687 195.74043 142.21205]\n",
      "300 Cost: 3.529826 \n",
      "Prediction:\n",
      " [154.32329 181.79082 181.35652 195.73996 142.21175]\n",
      "310 Cost: 3.521017 \n",
      "Prediction:\n",
      " [154.31964 181.79494 181.35622 195.73949 142.2115 ]\n",
      "320 Cost: 3.512226 \n",
      "Prediction:\n",
      " [154.316   181.79906 181.35593 195.73904 142.21126]\n",
      "330 Cost: 3.5034592 \n",
      "Prediction:\n",
      " [154.31236 181.80316 181.35559 195.73856 142.211  ]\n",
      "340 Cost: 3.4947236 \n",
      "Prediction:\n",
      " [154.30872 181.80725 181.35529 195.7381  142.21074]\n",
      "350 Cost: 3.4859974 \n",
      "Prediction:\n",
      " [154.30508 181.81136 181.35498 195.73763 142.2105 ]\n",
      "360 Cost: 3.477324 \n",
      "Prediction:\n",
      " [154.30145 181.81541 181.35464 195.73715 142.21024]\n",
      "370 Cost: 3.4686265 \n",
      "Prediction:\n",
      " [154.29784 181.81952 181.35432 195.7367  142.20999]\n",
      "380 Cost: 3.4599922 \n",
      "Prediction:\n",
      " [154.2942  181.82358 181.35402 195.73622 142.20972]\n",
      "390 Cost: 3.4513798 \n",
      "Prediction:\n",
      " [154.2906  181.82765 181.35371 195.73576 142.20947]\n",
      "400 Cost: 3.4427695 \n",
      "Prediction:\n",
      " [154.287   181.83173 181.3534  195.7353  142.20921]\n",
      "410 Cost: 3.4342282 \n",
      "Prediction:\n",
      " [154.2834  181.83577 181.3531  195.73483 142.20895]\n",
      "420 Cost: 3.4256458 \n",
      "Prediction:\n",
      " [154.27982 181.83986 181.3528  195.73439 142.20872]\n",
      "430 Cost: 3.4171379 \n",
      "Prediction:\n",
      " [154.27621 181.84389 181.3525  195.73392 142.20845]\n",
      "440 Cost: 3.4086387 \n",
      "Prediction:\n",
      " [154.27263 181.84792 181.35216 195.73346 142.20819]\n",
      "450 Cost: 3.400153 \n",
      "Prediction:\n",
      " [154.26906 181.85197 181.35187 195.733   142.20795]\n",
      "460 Cost: 3.3917222 \n",
      "Prediction:\n",
      " [154.26549 181.85599 181.35155 195.73253 142.2077 ]\n",
      "470 Cost: 3.3832607 \n",
      "Prediction:\n",
      " [154.26189 181.86002 181.35124 195.73209 142.20746]\n",
      "480 Cost: 3.3748736 \n",
      "Prediction:\n",
      " [154.25833 181.86403 181.35094 195.7316  142.20718]\n",
      "490 Cost: 3.3664908 \n",
      "Prediction:\n",
      " [154.25479 181.86806 181.35063 195.73117 142.20695]\n",
      "500 Cost: 3.3581283 \n",
      "Prediction:\n",
      " [154.25124 181.87207 181.35033 195.73071 142.20673]\n",
      "510 Cost: 3.349788 \n",
      "Prediction:\n",
      " [154.24767 181.87605 181.35    195.73026 142.20644]\n",
      "520 Cost: 3.3414578 \n",
      "Prediction:\n",
      " [154.24413 181.88008 181.34973 195.72981 142.2062 ]\n",
      "530 Cost: 3.333186 \n",
      "Prediction:\n",
      " [154.2406  181.88406 181.34941 195.72935 142.20596]\n",
      "540 Cost: 3.324924 \n",
      "Prediction:\n",
      " [154.23705 181.88803 181.3491  195.72888 142.20569]\n",
      "550 Cost: 3.3166778 \n",
      "Prediction:\n",
      " [154.23354 181.89203 181.3488  195.72844 142.20546]\n",
      "560 Cost: 3.3084724 \n",
      "Prediction:\n",
      " [154.23001 181.896   181.34851 195.728   142.2052 ]\n",
      "570 Cost: 3.300244 \n",
      "Prediction:\n",
      " [154.22646 181.89995 181.34816 195.7275  142.20494]\n",
      "580 Cost: 3.2920642 \n",
      "Prediction:\n",
      " [154.22295 181.90393 181.34789 195.72708 142.20471]\n",
      "590 Cost: 3.2839134 \n",
      "Prediction:\n",
      " [154.21945 181.9079  181.34758 195.72664 142.20447]\n",
      "600 Cost: 3.275766 \n",
      "Prediction:\n",
      " [154.21593 181.91185 181.34727 195.72618 142.20421]\n",
      "610 Cost: 3.2677016 \n",
      "Prediction:\n",
      " [154.21245 181.91579 181.34698 195.72571 142.20398]\n",
      "620 Cost: 3.2595763 \n",
      "Prediction:\n",
      " [154.20894 181.91975 181.3467  195.7253  142.20374]\n",
      "630 Cost: 3.2515278 \n",
      "Prediction:\n",
      " [154.20544 181.92368 181.34639 195.72484 142.20348]\n",
      "640 Cost: 3.2434916 \n",
      "Prediction:\n",
      " [154.20195 181.9276  181.34608 195.72438 142.20323]\n",
      "650 Cost: 3.2354805 \n",
      "Prediction:\n",
      " [154.19849 181.93153 181.3458  195.72395 142.203  ]\n",
      "660 Cost: 3.2274597 \n",
      "Prediction:\n",
      " [154.19499 181.93546 181.34547 195.72348 142.20276]\n",
      "670 Cost: 3.219499 \n",
      "Prediction:\n",
      " [154.19153 181.93936 181.34517 195.72305 142.20251]\n",
      "680 Cost: 3.2115421 \n",
      "Prediction:\n",
      " [154.18806 181.94328 181.34488 195.7226  142.20227]\n",
      "690 Cost: 3.2036254 \n",
      "Prediction:\n",
      " [154.18462 181.94719 181.34459 195.72215 142.20201]\n",
      "700 Cost: 3.195717 \n",
      "Prediction:\n",
      " [154.18114 181.95107 181.34427 195.7217  142.20177]\n",
      "710 Cost: 3.1878314 \n",
      "Prediction:\n",
      " [154.17769 181.95497 181.344   195.72127 142.20154]\n",
      "720 Cost: 3.179966 \n",
      "Prediction:\n",
      " [154.17424 181.95886 181.3437  195.72084 142.2013 ]\n",
      "730 Cost: 3.1721122 \n",
      "Prediction:\n",
      " [154.17078 181.96274 181.3434  195.72037 142.20103]\n",
      "740 Cost: 3.1642957 \n",
      "Prediction:\n",
      " [154.16736 181.96661 181.34308 195.71994 142.20078]\n",
      "750 Cost: 3.1565177 \n",
      "Prediction:\n",
      " [154.16393 181.97047 181.34279 195.71948 142.20055]\n",
      "760 Cost: 3.1487472 \n",
      "Prediction:\n",
      " [154.16049 181.97433 181.3425  195.71906 142.20032]\n",
      "770 Cost: 3.1410012 \n",
      "Prediction:\n",
      " [154.15707 181.9782  181.34221 195.71861 142.20007]\n",
      "780 Cost: 3.1332393 \n",
      "Prediction:\n",
      " [154.15363 181.98206 181.34192 195.71817 142.19983]\n",
      "790 Cost: 3.1255212 \n",
      "Prediction:\n",
      " [154.15022 181.98592 181.34161 195.71773 142.1996 ]\n",
      "800 Cost: 3.1178725 \n",
      "Prediction:\n",
      " [154.14682 181.98973 181.34132 195.7173  142.19934]\n",
      "810 Cost: 3.1101573 \n",
      "Prediction:\n",
      " [154.14342 181.9936  181.34102 195.71686 142.19911]\n",
      "820 Cost: 3.1025212 \n",
      "Prediction:\n",
      " [154.14001 181.99744 181.34074 195.71643 142.19887]\n",
      "830 Cost: 3.0948892 \n",
      "Prediction:\n",
      " [154.13661 182.00127 181.34045 195.71599 142.19862]\n",
      "840 Cost: 3.0872865 \n",
      "Prediction:\n",
      " [154.13324 182.0051  181.34015 195.71555 142.1984 ]\n",
      "850 Cost: 3.0797117 \n",
      "Prediction:\n",
      " [154.12984 182.0089  181.33986 195.71512 142.19817]\n",
      "860 Cost: 3.0721545 \n",
      "Prediction:\n",
      " [154.12646 182.01271 181.33957 195.71468 142.1979 ]\n",
      "870 Cost: 3.0646179 \n",
      "Prediction:\n",
      " [154.1231  182.01653 181.3393  195.71425 142.1977 ]\n",
      "880 Cost: 3.0570793 \n",
      "Prediction:\n",
      " [154.11972 182.02034 181.339   195.71384 142.19745]\n",
      "890 Cost: 3.0495849 \n",
      "Prediction:\n",
      " [154.11635 182.02412 181.3387  195.71338 142.1972 ]\n",
      "900 Cost: 3.0420983 \n",
      "Prediction:\n",
      " [154.11298 182.02791 181.3384  195.71295 142.19698]\n",
      "910 Cost: 3.0346417 \n",
      "Prediction:\n",
      " [154.10962 182.03171 181.33813 195.71252 142.19675]\n",
      "920 Cost: 3.0272057 \n",
      "Prediction:\n",
      " [154.10626 182.03548 181.33783 195.7121  142.1965 ]\n",
      "930 Cost: 3.019786 \n",
      "Prediction:\n",
      " [154.10292 182.03926 181.33754 195.71165 142.19627]\n",
      "940 Cost: 3.0123734 \n",
      "Prediction:\n",
      " [154.09958 182.04305 181.33725 195.71123 142.19603]\n",
      "950 Cost: 3.005009 \n",
      "Prediction:\n",
      " [154.09624 182.0468  181.33696 195.7108  142.1958 ]\n",
      "960 Cost: 2.9976506 \n",
      "Prediction:\n",
      " [154.0929  182.05057 181.3367  195.71039 142.19557]\n",
      "970 Cost: 2.9902897 \n",
      "Prediction:\n",
      " [154.08955 182.05432 181.33638 195.70995 142.19531]\n",
      "980 Cost: 2.9830089 \n",
      "Prediction:\n",
      " [154.08624 182.05806 181.3361  195.7095  142.19508]\n",
      "990 Cost: 2.975716 \n",
      "Prediction:\n",
      " [154.08293 182.06181 181.33583 195.7091  142.19487]\n",
      "1000 Cost: 2.9684687 \n",
      "Prediction:\n",
      " [154.0796  182.06552 181.33554 195.70866 142.19461]\n",
      "1010 Cost: 2.9611845 \n",
      "Prediction:\n",
      " [154.07631 182.06929 181.33525 195.70825 142.1944 ]\n",
      "1020 Cost: 2.9539495 \n",
      "Prediction:\n",
      " [154.07298 182.07301 181.33498 195.70781 142.19417]\n",
      "1030 Cost: 2.9467437 \n",
      "Prediction:\n",
      " [154.06967 182.07672 181.33469 195.70738 142.19392]\n",
      "1040 Cost: 2.9395258 \n",
      "Prediction:\n",
      " [154.06638 182.08046 181.3344  195.70697 142.19371]\n",
      "1050 Cost: 2.9323678 \n",
      "Prediction:\n",
      " [154.06311 182.08418 181.33412 195.70656 142.19348]\n",
      "1060 Cost: 2.92522 \n",
      "Prediction:\n",
      " [154.0598  182.08786 181.33382 195.70612 142.19322]\n",
      "1070 Cost: 2.9180782 \n",
      "Prediction:\n",
      " [154.05652 182.09158 181.33356 195.70572 142.19302]\n",
      "1080 Cost: 2.9109464 \n",
      "Prediction:\n",
      " [154.05324 182.09529 181.33327 195.70529 142.19276]\n",
      "1090 Cost: 2.9038785 \n",
      "Prediction:\n",
      " [154.04996 182.09895 181.33298 195.70488 142.19254]\n",
      "1100 Cost: 2.8968003 \n",
      "Prediction:\n",
      " [154.04669 182.10266 181.33272 195.70444 142.19232]\n",
      "1110 Cost: 2.8897393 \n",
      "Prediction:\n",
      " [154.04343 182.10634 181.33241 195.70401 142.19208]\n",
      "1120 Cost: 2.8826911 \n",
      "Prediction:\n",
      " [154.04015 182.11002 181.33214 195.7036  142.19185]\n",
      "1130 Cost: 2.8756893 \n",
      "Prediction:\n",
      " [154.03691 182.1137  181.33186 195.7032  142.19164]\n",
      "1140 Cost: 2.8687174 \n",
      "Prediction:\n",
      " [154.03368 182.11736 181.33159 195.70277 142.1914 ]\n",
      "1150 Cost: 2.8616955 \n",
      "Prediction:\n",
      " [154.03041 182.12103 181.33128 195.70235 142.19116]\n",
      "1160 Cost: 2.8547661 \n",
      "Prediction:\n",
      " [154.02718 182.12468 181.33102 195.70195 142.19095]\n",
      "1170 Cost: 2.8478384 \n",
      "Prediction:\n",
      " [154.02393 182.12831 181.33073 195.7015  142.1907 ]\n",
      "1180 Cost: 2.8409247 \n",
      "Prediction:\n",
      " [154.0207  182.13197 181.33047 195.7011  142.19049]\n",
      "1190 Cost: 2.8340058 \n",
      "Prediction:\n",
      " [154.01746 182.1356  181.33017 195.70068 142.19026]\n",
      "1200 Cost: 2.827125 \n",
      "Prediction:\n",
      " [154.01422 182.13924 181.3299  195.70027 142.19003]\n",
      "1210 Cost: 2.8202431 \n",
      "Prediction:\n",
      " [154.01102 182.1429  181.32962 195.69987 142.18982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220 Cost: 2.8133929 \n",
      "Prediction:\n",
      " [154.00778 182.14651 181.32933 195.69943 142.18958]\n",
      "1230 Cost: 2.8065903 \n",
      "Prediction:\n",
      " [154.00458 182.15013 181.32907 195.69904 142.18936]\n",
      "1240 Cost: 2.7997842 \n",
      "Prediction:\n",
      " [154.00139 182.15376 181.3288  195.69862 142.18913]\n",
      "1250 Cost: 2.7930171 \n",
      "Prediction:\n",
      " [153.99817 182.15735 181.32852 195.6982  142.1889 ]\n",
      "1260 Cost: 2.7862558 \n",
      "Prediction:\n",
      " [153.99498 182.16095 181.32823 195.6978  142.18869]\n",
      "1270 Cost: 2.7794726 \n",
      "Prediction:\n",
      " [153.99178 182.16458 181.32797 195.6974  142.18846]\n",
      "1280 Cost: 2.772766 \n",
      "Prediction:\n",
      " [153.98859 182.16815 181.32768 195.69698 142.18822]\n",
      "1290 Cost: 2.766053 \n",
      "Prediction:\n",
      " [153.98541 182.17175 181.32741 195.69658 142.188  ]\n",
      "1300 Cost: 2.7593465 \n",
      "Prediction:\n",
      " [153.98221 182.17534 181.32713 195.69615 142.18779]\n",
      "1310 Cost: 2.7527225 \n",
      "Prediction:\n",
      " [153.97905 182.1789  181.32687 195.69574 142.18753]\n",
      "1320 Cost: 2.746037 \n",
      "Prediction:\n",
      " [153.97588 182.1825  181.3266  195.69536 142.18733]\n",
      "1330 Cost: 2.7394032 \n",
      "Prediction:\n",
      " [153.97269 182.18604 181.3263  195.69493 142.18709]\n",
      "1340 Cost: 2.7327747 \n",
      "Prediction:\n",
      " [153.96953 182.18962 181.32603 195.69452 142.18686]\n",
      "1350 Cost: 2.7261972 \n",
      "Prediction:\n",
      " [153.9664  182.19319 181.32578 195.69412 142.18666]\n",
      "1360 Cost: 2.7196279 \n",
      "Prediction:\n",
      " [153.96323 182.19673 181.32552 195.69371 142.18645]\n",
      "1370 Cost: 2.7130294 \n",
      "Prediction:\n",
      " [153.96008 182.20032 181.32524 195.69331 142.18622]\n",
      "1380 Cost: 2.706488 \n",
      "Prediction:\n",
      " [153.95692 182.20384 181.32495 195.69292 142.18599]\n",
      "1390 Cost: 2.6999648 \n",
      "Prediction:\n",
      " [153.9538  182.2074  181.32469 195.6925  142.18578]\n",
      "1400 Cost: 2.693457 \n",
      "Prediction:\n",
      " [153.95067 182.21094 181.32442 195.69212 142.18558]\n",
      "1410 Cost: 2.6869905 \n",
      "Prediction:\n",
      " [153.94753 182.21445 181.32416 195.6917  142.18533]\n",
      "1420 Cost: 2.6805015 \n",
      "Prediction:\n",
      " [153.9444  182.21799 181.32388 195.6913  142.18512]\n",
      "1430 Cost: 2.6740541 \n",
      "Prediction:\n",
      " [153.94127 182.2215  181.32361 195.6909  142.18489]\n",
      "1440 Cost: 2.6676202 \n",
      "Prediction:\n",
      " [153.93816 182.22502 181.32335 195.6905  142.18468]\n",
      "1450 Cost: 2.661192 \n",
      "Prediction:\n",
      " [153.93503 182.22853 181.32307 195.69011 142.18446]\n",
      "1460 Cost: 2.6548042 \n",
      "Prediction:\n",
      " [153.93193 182.23204 181.32281 195.68971 142.18425]\n",
      "1470 Cost: 2.6484067 \n",
      "Prediction:\n",
      " [153.92882 182.23555 181.32254 195.6893  142.18402]\n",
      "1480 Cost: 2.6420586 \n",
      "Prediction:\n",
      " [153.9257  182.23903 181.32228 195.6889  142.1838 ]\n",
      "1490 Cost: 2.6357086 \n",
      "Prediction:\n",
      " [153.9226  182.24251 181.32198 195.68848 142.18356]\n",
      "1500 Cost: 2.629361 \n",
      "Prediction:\n",
      " [153.91951 182.24602 181.32173 195.68811 142.18335]\n",
      "1510 Cost: 2.6230474 \n",
      "Prediction:\n",
      " [153.91643 182.24951 181.32147 195.68771 142.18315]\n",
      "1520 Cost: 2.6167698 \n",
      "Prediction:\n",
      " [153.91336 182.25299 181.32121 195.68732 142.18294]\n",
      "1530 Cost: 2.6104863 \n",
      "Prediction:\n",
      " [153.91028 182.25647 181.32095 195.68694 142.18271]\n",
      "1540 Cost: 2.6042252 \n",
      "Prediction:\n",
      " [153.9072  182.25993 181.32068 195.68652 142.1825 ]\n",
      "1550 Cost: 2.5979896 \n",
      "Prediction:\n",
      " [153.90413 182.2634  181.32042 195.68614 142.1823 ]\n",
      "1560 Cost: 2.5917616 \n",
      "Prediction:\n",
      " [153.90105 182.26685 181.32014 195.68573 142.18207]\n",
      "1570 Cost: 2.5855558 \n",
      "Prediction:\n",
      " [153.898   182.27031 181.31989 195.68533 142.18185]\n",
      "1580 Cost: 2.579363 \n",
      "Prediction:\n",
      " [153.89493 182.27376 181.31963 195.68495 142.18166]\n",
      "1590 Cost: 2.573186 \n",
      "Prediction:\n",
      " [153.89186 182.27719 181.31935 195.68456 142.18141]\n",
      "1600 Cost: 2.5670328 \n",
      "Prediction:\n",
      " [153.88882 182.28065 181.31912 195.68417 142.18121]\n",
      "1610 Cost: 2.5609221 \n",
      "Prediction:\n",
      " [153.88579 182.28406 181.31883 195.68378 142.18098]\n",
      "1620 Cost: 2.5547788 \n",
      "Prediction:\n",
      " [153.88272 182.28749 181.31857 195.6834  142.18077]\n",
      "1630 Cost: 2.5486646 \n",
      "Prediction:\n",
      " [153.8797  182.29094 181.31831 195.683   142.18056]\n",
      "1640 Cost: 2.542583 \n",
      "Prediction:\n",
      " [153.87663 182.29433 181.31804 195.68259 142.18033]\n",
      "1650 Cost: 2.5365121 \n",
      "Prediction:\n",
      " [153.87363 182.29776 181.31778 195.6822  142.18013]\n",
      "1660 Cost: 2.5304408 \n",
      "Prediction:\n",
      " [153.87057 182.30116 181.3175  195.68181 142.1799 ]\n",
      "1670 Cost: 2.524419 \n",
      "Prediction:\n",
      " [153.86758 182.30458 181.31726 195.68146 142.1797 ]\n",
      "1680 Cost: 2.5183885 \n",
      "Prediction:\n",
      " [153.86456 182.308   181.31702 195.68106 142.1795 ]\n",
      "1690 Cost: 2.512398 \n",
      "Prediction:\n",
      " [153.86154 182.31137 181.31674 195.68066 142.17928]\n",
      "1700 Cost: 2.506415 \n",
      "Prediction:\n",
      " [153.85855 182.31479 181.31651 195.68027 142.17908]\n",
      "1710 Cost: 2.5004494 \n",
      "Prediction:\n",
      " [153.85555 182.31816 181.31624 195.6799  142.17886]\n",
      "1720 Cost: 2.4944775 \n",
      "Prediction:\n",
      " [153.85254 182.32155 181.31596 195.67952 142.17865]\n",
      "1730 Cost: 2.488571 \n",
      "Prediction:\n",
      " [153.84956 182.32492 181.31572 195.67912 142.17844]\n",
      "1740 Cost: 2.4826207 \n",
      "Prediction:\n",
      " [153.84654 182.3283  181.31544 195.67874 142.17822]\n",
      "1750 Cost: 2.4767194 \n",
      "Prediction:\n",
      " [153.84355 182.33167 181.3152  195.67834 142.17801]\n",
      "1760 Cost: 2.4708629 \n",
      "Prediction:\n",
      " [153.84058 182.335   181.31494 195.67795 142.17781]\n",
      "1770 Cost: 2.4649785 \n",
      "Prediction:\n",
      " [153.8376  182.33838 181.31468 195.67758 142.17761]\n",
      "1780 Cost: 2.4591188 \n",
      "Prediction:\n",
      " [153.83463 182.34174 181.31442 195.6772  142.1774 ]\n",
      "1790 Cost: 2.453275 \n",
      "Prediction:\n",
      " [153.83165 182.34508 181.31415 195.67682 142.17717]\n",
      "1800 Cost: 2.4474137 \n",
      "Prediction:\n",
      " [153.82866 182.34845 181.3139  195.67644 142.17697]\n",
      "1810 Cost: 2.4416492 \n",
      "Prediction:\n",
      " [153.82571 182.35176 181.31364 195.67604 142.17673]\n",
      "1820 Cost: 2.4358478 \n",
      "Prediction:\n",
      " [153.82275 182.3551  181.31339 195.67569 142.17654]\n",
      "1830 Cost: 2.4300735 \n",
      "Prediction:\n",
      " [153.8198  182.35844 181.31316 195.67531 142.17635]\n",
      "1840 Cost: 2.4243274 \n",
      "Prediction:\n",
      " [153.81686 182.36177 181.3129  195.67494 142.17615]\n",
      "1850 Cost: 2.4185781 \n",
      "Prediction:\n",
      " [153.8139  182.3651  181.31265 195.67455 142.17593]\n",
      "1860 Cost: 2.412856 \n",
      "Prediction:\n",
      " [153.81096 182.36841 181.3124  195.67415 142.17572]\n",
      "1870 Cost: 2.4071317 \n",
      "Prediction:\n",
      " [153.80803 182.37173 181.31213 195.6738  142.17552]\n",
      "1880 Cost: 2.4014416 \n",
      "Prediction:\n",
      " [153.80508 182.37503 181.31187 195.6734  142.17531]\n",
      "1890 Cost: 2.3957803 \n",
      "Prediction:\n",
      " [153.80215 182.37833 181.31165 195.67305 142.1751 ]\n",
      "1900 Cost: 2.3900928 \n",
      "Prediction:\n",
      " [153.79922 182.38162 181.31134 195.67265 142.17488]\n",
      "1910 Cost: 2.3844686 \n",
      "Prediction:\n",
      " [153.79631 182.38492 181.31113 195.6723  142.1747 ]\n",
      "1920 Cost: 2.3788328 \n",
      "Prediction:\n",
      " [153.7934  182.38821 181.31087 195.6719  142.1745 ]\n",
      "1930 Cost: 2.3732157 \n",
      "Prediction:\n",
      " [153.79048 182.3915  181.31061 195.67154 142.17429]\n",
      "1940 Cost: 2.3676028 \n",
      "Prediction:\n",
      " [153.78758 182.3948  181.31038 195.67117 142.17409]\n",
      "1950 Cost: 2.3620093 \n",
      "Prediction:\n",
      " [153.78465 182.39807 181.31012 195.67078 142.17386]\n",
      "1960 Cost: 2.3564446 \n",
      "Prediction:\n",
      " [153.78175 182.40134 181.30986 195.67041 142.17368]\n",
      "1970 Cost: 2.3509073 \n",
      "Prediction:\n",
      " [153.77884 182.40457 181.3096  195.67003 142.17345]\n",
      "1980 Cost: 2.345373 \n",
      "Prediction:\n",
      " [153.77599 182.40787 181.30937 195.66968 142.17326]\n",
      "1990 Cost: 2.3398552 \n",
      "Prediction:\n",
      " [153.77309 182.41112 181.30913 195.66931 142.17308]\n",
      "2000 Cost: 2.3343465 \n",
      "Prediction:\n",
      " [153.7702  182.41437 181.30887 195.66893 142.17285]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={x1: x1_data,x2: x2_data,x3: x3_data, Y: y_data})\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost:\", cost_val, \"\\nPrediction:\\n\",hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습2\n",
    "\n",
    "### using matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[73., 80., 75.],[93., 88., 93.],\n",
    "          [89., 91., 90.],[96., 98., 100.],[73., 66., 70.]]\n",
    "y_data = [[152.],[185.],[180.],[196.],[142.]]\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  51942.254 \n",
      "Prediction:\n",
      " [[-52.863316]\n",
      " [-57.25903 ]\n",
      " [-59.734184]\n",
      " [-62.322258]\n",
      " [-44.681507]]\n",
      "500 Cost:  2.9795926 \n",
      "Prediction:\n",
      " [[149.45306]\n",
      " [185.72726]\n",
      " [179.78268]\n",
      " [198.4539 ]\n",
      " [140.65341]]\n",
      "1000 Cost:  2.880814 \n",
      "Prediction:\n",
      " [[149.54158]\n",
      " [185.67047]\n",
      " [179.81473]\n",
      " [198.43881]\n",
      " [140.61127]]\n",
      "1500 Cost:  2.7920883 \n",
      "Prediction:\n",
      " [[149.62086]\n",
      " [185.61995]\n",
      " [179.84389]\n",
      " [198.42204]\n",
      " [140.57692]]\n",
      "2000 Cost:  2.7113812 \n",
      "Prediction:\n",
      " [[149.69208]\n",
      " [185.57489]\n",
      " [179.8705 ]\n",
      " [198.4039 ]\n",
      " [140.54935]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습3\n",
    "\n",
    "### loading data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n",
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]] 6\n",
      "(6, 1)\n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]] 6\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('./data/data-01-test-score.csv', delimiter = ',', dtype = np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(x_data, len(x_data))\n",
    "print(y_data.shape)\n",
    "print(y_data, len(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1], name = 'weight'))\n",
    "b = tf.Variable(tf.random_normal([1], name = 'bias'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimiozer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 9553.77 \n",
      "Prediction\n",
      " [[58.677845]\n",
      " [73.79402 ]\n",
      " [70.905136]\n",
      " [79.59475 ]\n",
      " [54.97008 ]\n",
      " [44.24841 ]]\n",
      "500 cost: 6.7646885 \n",
      "Prediction\n",
      " [[150.60619]\n",
      " [183.96571]\n",
      " [179.63243]\n",
      " [197.89195]\n",
      " [139.00954]\n",
      " [105.99181]]\n",
      "1000 cost: 6.3732753 \n",
      "Prediction\n",
      " [[150.79178 ]\n",
      " [183.89221 ]\n",
      " [179.72142 ]\n",
      " [197.88617 ]\n",
      " [138.96416 ]\n",
      " [105.764565]]\n",
      "1500 cost: 6.0405736 \n",
      "Prediction\n",
      " [[150.94984 ]\n",
      " [183.8319  ]\n",
      " [179.79906 ]\n",
      " [197.87401 ]\n",
      " [138.93541 ]\n",
      " [105.564224]]\n",
      "2000 cost: 5.7519417 \n",
      "Prediction\n",
      " [[151.08461]\n",
      " [183.78265]\n",
      " [179.86703]\n",
      " [197.85658]\n",
      " [138.92055]\n",
      " [105.38682]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict ={X : x_data, Y: y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(step, \"cost:\", cost_val,'\\nPrediction\\n',hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score will be  [[189.17007]]\n",
      "Other score will be  [[189.3888 ]\n",
      " [170.58374]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Your score will be \", sess.run(hypothesis, feed_dict = {X: [[100, 70, 101]]}))\n",
    "print(\"Other score will be \", sess.run(hypothesis, feed_dict = {X: [[60,70,110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습4\n",
    "\n",
    "### Queue Runner\n",
    "\n",
    "\n",
    "<img src=\"./images/queue_runner.png\" width=45%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1'\n",
      "b'2'\n",
      "b'3'\n",
      "b'1'\n",
      "b'2'\n",
      "b'3'\n",
      "b'1'\n",
      "b'2'\n",
      "b'3'\n",
      "b'1'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([\"1\",\"2\",\"3\"],shuffle=False)\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord,sess=sess)\n",
    "\n",
    "    for step in range(10):\n",
    "        print(sess.run(filename_queue.dequeue()) )\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습5\n",
    "\n",
    "### queue runner and batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_defaults = [[0.],[0.],[0.],[0.]]\n",
    "xy = tf.decode_csv(value, record_defaults = record_defaults)\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1], name = 'weight'))\n",
    "b = tf.Variable(tf.random_normal([1], name = 'bias'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Field 0 in record 0 is not a valid float: # EXAM1\n",
      "\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], field_delim=\",\", na_value=\"\", select_cols=[], use_quote_delim=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReaderReadV2:1, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_0)]]\n",
      "\t [[Node: DecodeCSV/_18 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_DecodeCSV\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_10_batch_2/fifo_queue' is closed and has insufficient elements (requested 10, current size 1)\n\t [[Node: batch_2 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_2/fifo_queue, batch_2/n)]]\n\nCaused by op 'batch_2', defined at:\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-3e97b9057a5f>\", line 3, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size = 10)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 988, in batch\n    name=name)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 762, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 476, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3480, in queue_dequeue_many_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_10_batch_2/fifo_queue' is closed and has insufficient elements (requested 10, current size 1)\n\t [[Node: batch_2 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_2/fifo_queue, batch_2/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_10_batch_2/fifo_queue' is closed and has insufficient elements (requested 10, current size 1)\n\t [[Node: batch_2 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_2/fifo_queue, batch_2/n)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ab855c12703a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     cost_val, hy_val, _ = sess.run(\n\u001b[1;32m      4\u001b[0m         [cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_10_batch_2/fifo_queue' is closed and has insufficient elements (requested 10, current size 1)\n\t [[Node: batch_2 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_2/fifo_queue, batch_2/n)]]\n\nCaused by op 'batch_2', defined at:\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-3e97b9057a5f>\", line 3, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size = 10)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 988, in batch\n    name=name)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py\", line 762, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 476, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3480, in queue_dequeue_many_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): FIFOQueue '_10_batch_2/fifo_queue' is closed and has insufficient elements (requested 10, current size 1)\n\t [[Node: batch_2 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_2/fifo_queue, batch_2/n)]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
